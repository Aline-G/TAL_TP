{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Sujet 1 : Evaluation de deux plateformes open source d'analyse linguistique</u>\n",
    "\n",
    "## <u> I - Evaluation de l'analyse morpho-syntaxique </u>\n",
    "\n",
    "##### 1) Utiliser le corpus annoté « pos_reference.txt.lima » pour extraire les phrases ayant servi pour produire ce corpus annoté et sauvegarder le résultat dans le fichier « pos_test.txt  »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(fileIn, fileOut):\n",
    "    fileI = open(fileIn,'r')\n",
    "    fileO = open(fileOut,'w')\n",
    "\n",
    "    for line in fileI:\n",
    "\n",
    "        tuples = line.split()\n",
    "        if tuples:\n",
    "            # On souhaite récupérer l'entièreté de la ligne à l'exception du dernier mot\n",
    "            # qui est l'annotation\n",
    "            for i in range(len(tuples)-1):\n",
    "                fileO.write(tuples[i]+\" \")\n",
    "        else:\n",
    "            # Si on arrive à une ligne vide on saute une ligne c'est un changement de phrase \n",
    "            fileO.write(\"\\n\")\n",
    "\n",
    "    fileI.close()\n",
    "    fileO.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileIn = \"pos_reference.txt.lima\"\n",
    "fileOut = \"pos_test.txt\"\n",
    "\n",
    "getText(fileIn,fileOut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Convertir  les  tags  du  corpus  annoté  « pos_reference.txt.lima »  en  tags  universels  et sauvegarder le résultat dans le fichier « pos_reference.txt.univ ». Il faut utiliser les deux tables de correspondance « POSTags_LIMA_PTB_Linux.txt » et « POSTags_PTB_Universal_Linux.txt » pour réaliser cette transformation (LIMA => PTB => Universal). \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setTagUniv(fileIn, fileRef1,fileRef2, fileOut):\n",
    "    fileI = open(fileIn,'r')\n",
    "    fileR1 = open(fileRef1,'r')\n",
    "    fileR2 = open(fileRef2,'r')\n",
    "    fileO = open(fileOut,'w')\n",
    "\n",
    "    my_dico1 = {}\n",
    "    my_dico2 = {}\n",
    "\n",
    "    #on crée deux dictionnaires à partir des tags de reference\n",
    "    for line in fileR1:\n",
    "        tuples = line.split()\n",
    "        my_dico1[tuples[0]] = tuples[1]\n",
    "    fileR1.close()\n",
    "\n",
    "    for line in fileR2:\n",
    "        tuples = line.split()\n",
    "        my_dico2[tuples[0]] = tuples[1]\n",
    "    fileR2.close()\n",
    "\n",
    "    # modification des tags vers les tags univ\n",
    "    for l in fileI:\n",
    "        tup = l.split()\n",
    "        if tup:\n",
    "            # on écrit le groupe de mots initial\n",
    "            for i in range(len(tup)-1):\n",
    "                    fileO.write(tup[i]+\" \")\n",
    "            temp = my_dico1[tup[len(tup)-1]]\n",
    "\n",
    "            fileO.write('\\t'+ my_dico2[temp])\n",
    "            fileO.write('\\n')\n",
    "        else:\n",
    "            fileO.write(\"\\n\")\n",
    "\n",
    "    fileI.close()\n",
    "    fileO.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileIn = \"pos_reference.txt.lima\"\n",
    "fileRef1 = \"POSTags_LIMA_PTB_Linux.txt\"\n",
    "fileRef2 = \"POSTags_PTB_Universal_Linux.txt\"\n",
    "fileOut = \"pos_reference.txt.univ\"\n",
    "\n",
    "\n",
    "setTagUniv(fileIn,fileRef1,fileRef2,fileOut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Lancer les deux POS taggers sur le fichier « pos_test.txt ». Les résultats doivent avoir le format du  corpus  annoté  « pos_reference.txt.lima »  (2  colonnes  séparées  par  une  tabulation)  et doivent être sauvegardés respectivement dans les fichiers suivants : \n",
    "-  pos_test.txt.pos.stanford \n",
    "-  pos_test.txt.pos.nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Convertir les résultats des deux POS taggers en utilisant les étiquettes universelles (Annexe 1). Il faut utiliser la table de correspondance « POSTags_PTB_Universal_Linux.txt » pour réaliser cette  transformation  (PTB => Universal).  Les  résultats  de  cette  conversion  doivent  être sauvegardés respectivement dans les fichiers suivants : \n",
    "-  pos_test.txt.pos.stanford.univ \n",
    "-  pos_test.txt.pos.nltk.univ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Lancer l’évaluation des deux POS taggers. Pour réaliser cette évaluation, il faut supprimer la ligne vide (séparant les phrases) dans le de fichier de référence « pos_reference.txt.univ » : \n",
    "-  python evaluate.py pos_test.txt.pos.stanford.univ pos_reference.txt.univ \n",
    "-  python evaluate.py pos_test.txt.pos.nltk.univ pos_reference.txt.univ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Quelles conclusions vous pouvez avoir à partir des résultats d’évaluation des deux POS taggers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> II. Evaluation de la reconnaissance d’entités nommées </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Utiliser le corpus annoté « ne_reference.txt.conll » pour extraire les phrases ayant servi pour produire ce corpus annoté et sauvegarder le résultat dans le fichier « ne_test.txt ». Dans ce corpus, une ligne vide indique la fin de la phrase courante. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Lancer les deux NE recognizers sur le fichier « ne_test.txt ». Les résultats doivent avoir le format  du  corpus  annoté  « ne_reference.txt.conll »  (2  colonnes  séparées  par  une tabulation) et doivent être sauvegardés respectivement dans les fichiers suivants : \n",
    "-  ne_test.txt.ne.stanford \n",
    "-  ne_test.txt.ne.nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Convertir  les  résultats  des  deux  NE  recognizers  en  utilisant  les  étiquettes  CoNLL-2003 (https://www.clips.uantwerpen.be/conll2003/ner/  -Annexe  2-).  Les  résultats  de  cette conversion doivent être sauvegardés respectivement dans les fichiers suivants : \n",
    "-  ne_test.txt.ne.stanford.conll \n",
    "-  ne_test.txt.ne.nltk.conll "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Lancer  l’évaluation  des  deux  NE  recognizers.  Pour  réaliser  cette  évaluation,  il  faut supprimer  la  ligne  vide  (séparant  les  phrases)  dans  le  de  fichier  de  référence « ne_reference.txt.conll »: \n",
    "-  python evaluate.py ne_test.txt.ne.stanford.conll ne_reference.txt.conll \n",
    "-  python evaluate.py ne_test.txt.ne.nltk.conll ne_reference.txt.conll "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Quelles conclusions vous pouvez avoir à partir des résultats d’évaluation des deux NE recognizers."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41b1dee31b2b8bd9e4c2bb4bb44ed11c551d034648e4147e6c7c5ae9371a102e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
